{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flevoland.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AutomaticHourglass/SAR1/blob/master/Flevoland.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "MS3N2OnsmKLc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# for fn in uploaded.keys():\n",
        "#   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "#       name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yH16KwZqhYou",
        "colab_type": "code",
        "outputId": "54230cea-c990-46c8-de12-64f66dd105f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pydrive\n",
        "# !pip install lightgbm\n",
        "!pip install catboost\n",
        "!pip install xgboost\n",
        "!pip install --upgrade --user hmmlearn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.6.7)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.11.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.11.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.5)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.6/dist-packages (0.12.2)\n",
            "Requirement already satisfied: pandas>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from catboost) (0.22.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.11.0)\n",
            "Requirement already satisfied: enum34 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.6)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.14.6)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.1->catboost) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.1->catboost) (2018.9)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.7.post4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.14.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.1.0)\n",
            "Requirement already up-to-date: hmmlearn in /root/.local/lib/python3.6/site-packages (0.2.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.16 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (0.20.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.16->hmmlearn) (1.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bcewqNdDGzuQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !git clone --recursive https://github.com/Microsoft/LightGBM\n",
        "# !cd LightGBM\n",
        "# !mkdir build ; cd build\n",
        "# !cmake -DUSE_GPU=1 ..\n",
        "# # if you have installed NVIDIA CUDA to a customized location, you should specify paths to OpenCL headers and library like the following:\n",
        "# # cmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..\n",
        "# !make -j$(nproc)\n",
        "# !cd ..\n",
        "\n",
        "# !apt-get -qq install --no-install-recommends nvidia-375\n",
        "# # !apt-get -qq install --no-install-recommends nvidia-opencl-icd-375 nvidia-opencl-dev opencl-headers\n",
        "# # !apt-get -qq install --no-install-recommends git cmake build-essential libboost-dev libboost-system-dev libboost-filesystem-dev\n",
        "# # !pip install -qq lightgbm --install-option=--gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W2Ykn3RGDnxs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def download_file(file_id, filename):\n",
        "  import io\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "  # 1. Authenticate and create the PyDrive client.\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "\n",
        "  from googleapiclient.discovery import build\n",
        "  drive_service = build('drive', 'v3')\n",
        "\n",
        "  request = drive_service.files().get_media(fileId=file_id)\n",
        "  fh = io.FileIO(filename, 'wb')\n",
        "  downloader = MediaIoBaseDownload(fh, request)\n",
        "  done = False\n",
        "  while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eziibSdMNj96",
        "colab_type": "code",
        "outputId": "2e0e5be5-1850-4f11-f591-f13fafea418d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "thesis_base_folder_id = '0B1XCkiXOusbmX3ZiTF9GaWZfQlU'\n",
        "flevoland_data_id = '1tKZLH53sfawd9dKnTVA1CADWtC9qXgMO'\n",
        "flevoland_alim_samat_id = '1Xves_MigWqzC_DpZjRjgbXcGeqdT5twK'\n",
        "\n",
        "flevoland_data_name = 'flevoland_data.mat'\n",
        "\n",
        "data_source = 'alim'\n",
        "\n",
        "if data_source == 'alim':\n",
        "  download_file(flevoland_alim_samat_id,flevoland_data_name)\n",
        "  mat = scipy.io.loadmat('flevoland_data.mat')\n",
        "  data_img = np.real(np.array(mat['T3']))\n",
        "  label_roi_tr = np.array(mat['tr_label_img'])\n",
        "  label_roi_ts = np.array(mat['ts_label_img'])\n",
        "else:\n",
        "  download_file(flevoland_data_id,flevoland_data_name)\n",
        "  mat = scipy.io.loadmat('flevoland_data.mat')\n",
        "  data_img = np.real(np.array(mat['data']))\n",
        "  label_img = np.array(mat['label'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download 100%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lb3X4u6PoErk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# mat = scipy.io.loadmat('flevoland_data.mat')\n",
        "# data_img = np.real(np.array(mat['data']))\n",
        "# data_img = data_img[:,:,[1,2,4]]\n",
        "# r1 = data_img[:,:,0]/(data_img[:,:,3]+1e-6)\n",
        "# r2 = data_img[:,:,0]/(data_img[:,:,5]+1e-6)\n",
        "# r3 = data_img[:,:,3]/(data_img[:,:,5]+1e-6)\n",
        "\n",
        "# r1 = np.expand_dims(r1,axis=2)\n",
        "# r2 = np.expand_dims(r2,axis=2)\n",
        "# r3 = np.expand_dims(r3,axis=2)\n",
        "# span = data_img[:,:,0] + data_img[:,:,3] + data_img[:,:,5]\n",
        "# span = np.expand_dims(span,axis=2)\n",
        "\n",
        "# data_img = np.concatenate((data_img,r1,r2,r3),axis=2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BTmk8vKroUTT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def extract_patches(data_img, label_img, patch_size = (8,8), stride = 4, border = (3,3)):\n",
        "  from sklearn.feature_extraction import image\n",
        "\n",
        "  data_patches = image.extract_patches_2d(data_img,patch_size)\n",
        "  label_patches = image.extract_patches_2d(label_img,patch_size)\n",
        "\n",
        "  data_patches = data_patches[::stride]\n",
        "  label_patches = label_patches[::stride]\n",
        "\n",
        "  from collections import Counter\n",
        "\n",
        "  label = np.zeros(label_patches.shape[0])\n",
        "  cnt = 0\n",
        "\n",
        "  for patch in label_patches:\n",
        "    roi_patch = patch[border[0]:-border[0],border[1]:-border[1]]\n",
        "    c= Counter(patch.flatten())\n",
        "    x = c.most_common()[0][0]\n",
        "    label[cnt] = x\n",
        "    cnt += 1\n",
        "\n",
        "  ind = label>0\n",
        "  data_patches = data_patches[ind]\n",
        "  label_patches = label_patches[ind]\n",
        "  label -= 1\n",
        "  label = label[ind]\n",
        "  \n",
        "  return data_patches, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cYf2VP1l0KbN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if data_source != 'alim':\n",
        "  x1 = 200\n",
        "  x2 = 950\n",
        "  y1 = 200\n",
        "  y2 = 600\n",
        "  label_roi_ts = label_img.copy()\n",
        "  label_roi_ts[:x1,:] = 0\n",
        "  label_roi_ts[x2:,:] = 0\n",
        "  label_roi_ts[:,:y1] = 0\n",
        "  label_roi_ts[:,y2:] = 0\n",
        "  label_roi_tr = label_img.copy()\n",
        "  label_roi_tr[x1:x2,y1:y2] = 0\n",
        "\n",
        "  label_roi_tr[990:,320:360] = 0\n",
        "  label_roi_ts[990:,320:360] = label_img[990:,320:360]\n",
        "\n",
        "  ts_class = np.unique(label_roi_ts.flatten())\n",
        "  tr_class = np.unique(label_roi_tr.flatten())\n",
        "  print(ts_class)\n",
        "  print(tr_class)\n",
        "  print(list(set(tr_class) & set(ts_class)))\n",
        "  print(len(list(set(tr_class) & set(ts_class))))\n",
        "  print(label_img.shape)\n",
        "\n",
        "\n",
        "\n",
        "  plt.figure(figsize=(8,8))\n",
        "  plt.imshow(label_img, cmap='jet')\n",
        "  plt.show()\n",
        "  plt.figure(figsize=(8,8))\n",
        "  plt.imshow(label_roi_tr, cmap='jet')\n",
        "  plt.show()\n",
        "  plt.figure(figsize=(8,8))\n",
        "  plt.imshow(label_roi_ts, cmap='jet')\n",
        "  plt.show()\n",
        "\n",
        "# Vectorize 1x1 pixel\n",
        "data_vector_tr = data_img[label_roi_tr>0,:]\n",
        "data_vector_ts = data_img[label_roi_ts>0,:]\n",
        "label_vector_tr = label_roi_tr[label_roi_tr>0]\n",
        "label_vector_ts = label_roi_ts[label_roi_ts>0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-juftDLYIg6l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "patch_size = (12,12)\n",
        "stride = 4\n",
        "border = (2,2)\n",
        "data_tr, label_tr = extract_patches(data_img,label_roi_tr, patch_size=patch_size, stride=stride, border=border)\n",
        "data_ts, label_ts = extract_patches(data_img,label_roi_ts, patch_size=patch_size, stride=stride, border=border)\n",
        "\n",
        "print(data_ts.shape)\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "c_tr = Counter(label_tr)\n",
        "c_ts = Counter(label_ts)\n",
        "\n",
        "print(sorted(c_tr.items()))\n",
        "print(sorted(c_ts.items()))\n",
        "print(label_tr.shape)\n",
        "print(label_ts.shape)\n",
        "\n",
        "# Vectorize nxn tiles\n",
        "data_tr_vector = data_tr.reshape((data_tr.shape[0],-1))\n",
        "data_ts_vector = data_ts.reshape((data_ts.shape[0],-1))\n",
        "\n",
        "# # Data Augmentation\n",
        "# data_tr = np.concatenate((data_tr,data_tr[:,::-1,:,:],data_tr[:,:,::-1,:],data_tr[:,::-1,::-1,:]),axis=0)\n",
        "# label_tr = np.concatenate((label_tr,label_tr,label_tr,label_tr),axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4KoDct7Rod9L",
        "colab_type": "code",
        "outputId": "c9ce8f5e-febe-487e-b53c-f7ae1131c126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1448
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import RMSprop\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# np.random.seed(1)\n",
        "# tf.set_random_seed(2)\n",
        "\n",
        "if data_source == 'alim':\n",
        "  num_classes = 4\n",
        "else:\n",
        "  num_classes = 11\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "validate_gap = 10\n",
        "\n",
        "label_tr_cat = keras.utils.to_categorical(label_tr, num_classes)\n",
        "label_ts_cat = keras.utils.to_categorical(label_ts, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Conv2D(32, kernel_size=(5, 5),\n",
        "#                  activation='relu'))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, kernel_size=(3, 3),\n",
        "                 activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, kernel_size=(3, 3),\n",
        "                 activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Conv2D(32, kernel_size=(2, 2),\n",
        "#                  activation='relu'))\n",
        "\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Conv2D(128, kernel_size=(1, 1),\n",
        "#                  activation='relu'))\n",
        "\n",
        "# model.add(Dropout(0.1))\n",
        "model.add(Flatten())\n",
        "\n",
        "# model.add(Dense(512))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "\n",
        "# model.add(Dense(256))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Dropout(0.15))\n",
        "\n",
        "# model.add(Dense(128))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Dropout(0.15))\n",
        "\n",
        "# model.add(Dense(64))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dense(256))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adamax(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(data_tr, label_tr_cat,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,validation_data=(data_ts[::validate_gap], label_ts_cat[::validate_gap]))\n",
        "print(model.summary())\n",
        "\n",
        "# score = model.evaluate(data_ts, label_ts_cat, verbose=0)\n",
        "# print('Test loss:', score[0])\n",
        "# print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 1165 samples, validate on 16664 samples\n",
            "Epoch 1/20\n",
            "1165/1165 [==============================] - 6s 5ms/step - loss: 0.5045 - acc: 0.8369 - val_loss: 1.2133 - val_acc: 0.7622\n",
            "Epoch 2/20\n",
            "1165/1165 [==============================] - 2s 1ms/step - loss: 0.0721 - acc: 0.9708 - val_loss: 1.5460 - val_acc: 0.7510\n",
            "Epoch 3/20\n",
            "1165/1165 [==============================] - 2s 1ms/step - loss: 0.0594 - acc: 0.9803 - val_loss: 1.2014 - val_acc: 0.7844\n",
            "Epoch 4/20\n",
            "1165/1165 [==============================] - 2s 1ms/step - loss: 0.0248 - acc: 0.9923 - val_loss: 0.8621 - val_acc: 0.8044\n",
            "Epoch 5/20\n",
            "1165/1165 [==============================] - 2s 1ms/step - loss: 0.0234 - acc: 0.9923 - val_loss: 0.9717 - val_acc: 0.7946\n",
            "Epoch 6/20\n",
            "1165/1165 [==============================] - 2s 1ms/step - loss: 0.0255 - acc: 0.9923 - val_loss: 1.0491 - val_acc: 0.7906\n",
            "Epoch 7/20\n",
            "1165/1165 [==============================] - 2s 1ms/step - loss: 0.0159 - acc: 0.9931 - val_loss: 1.0766 - val_acc: 0.7828\n",
            "Epoch 8/20\n",
            "1165/1165 [==============================] - 2s 1ms/step - loss: 0.0144 - acc: 0.9940 - val_loss: 1.0046 - val_acc: 0.7915\n",
            "Epoch 9/20\n",
            "1165/1165 [==============================] - 2s 1ms/step - loss: 0.0072 - acc: 0.9983 - val_loss: 1.0414 - val_acc: 0.7909\n",
            "Epoch 10/20\n",
            "1165/1165 [==============================] - 2s 1ms/step - loss: 0.0081 - acc: 0.9983 - val_loss: 1.0749 - val_acc: 0.7895\n",
            "Epoch 11/20\n",
            "1165/1165 [==============================] - 2s 1ms/step - loss: 0.0293 - acc: 0.9957 - val_loss: 1.0561 - val_acc: 0.7926\n",
            "Epoch 12/20\n",
            "1165/1165 [==============================] - 2s 1ms/step - loss: 0.0155 - acc: 0.9931 - val_loss: 1.0422 - val_acc: 0.7929\n",
            "Epoch 13/20\n",
            "1165/1165 [==============================] - 2s 1ms/step - loss: 0.0440 - acc: 0.9854 - val_loss: 0.9574 - val_acc: 0.7900\n",
            "Epoch 14/20\n",
            "1165/1165 [==============================] - 2s 1ms/step - loss: 0.0198 - acc: 0.9906 - val_loss: 0.9172 - val_acc: 0.8039\n",
            "Epoch 15/20\n",
            "1165/1165 [==============================] - 2s 1ms/step - loss: 0.0115 - acc: 0.9948 - val_loss: 1.0760 - val_acc: 0.7860\n",
            "Epoch 16/20\n",
            "1165/1165 [==============================] - 2s 1ms/step - loss: 0.0117 - acc: 0.9983 - val_loss: 1.1424 - val_acc: 0.7836\n",
            "Epoch 17/20\n",
            "1165/1165 [==============================] - 2s 1ms/step - loss: 0.0201 - acc: 0.9897 - val_loss: 1.2447 - val_acc: 0.7704\n",
            "Epoch 18/20\n",
            "1165/1165 [==============================] - 2s 1ms/step - loss: 0.0196 - acc: 0.9931 - val_loss: 1.3210 - val_acc: 0.7626\n",
            "Epoch 19/20\n",
            "1165/1165 [==============================] - 2s 1ms/step - loss: 0.0159 - acc: 0.9948 - val_loss: 1.2127 - val_acc: 0.7741\n",
            "Epoch 20/20\n",
            "1165/1165 [==============================] - 2s 1ms/step - loss: 0.0081 - acc: 0.9983 - val_loss: 1.1444 - val_acc: 0.7838\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_1 (Batch (None, 8, 8, 6)           24        \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 6, 6, 128)         7040      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 6, 6, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2048)              8192      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               524544    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 688,924\n",
            "Trainable params: 684,560\n",
            "Non-trainable params: 4,364\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "spYQ_0GGQTX-",
        "colab_type": "code",
        "outputId": "0fd1f4e0-c3fd-4565-959f-285a5b7151da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "cell_type": "code",
      "source": [
        "# # cnn_predict = model.predict(data_ts, verbose=0)\n",
        "# # cnn_predict = np.argmax(cnn_predict,axis=1)\n",
        "\n",
        "# cnn_image_ts = label_roi_ts\n",
        "# cnn_image_ts = scipy.ndimage.binary_erosion(cnn_image_ts, structure=np.ones((1,1)))\n",
        "# cnn_image_ts[cnn_image_ts>0] = cnn_predict\n",
        "\n",
        "# plt.figure(figsize=(8,8))\n",
        "# plt.imshow(label_roi_ts, cmap='jet')\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(8,8))\n",
        "# plt.imshow(cnn_image_ts, cmap='jet')\n",
        "# plt.show()\n",
        "\n",
        "# # plt.imshow(label_img, cmap='jet')\n",
        "# # plt.show()\n",
        "# # plt.figure(figsize=(8,8))\n",
        "# # plt.imshow(label_roi_tr, cmap='jet')\n",
        "# # plt.show()\n",
        "# # plt.figure(figsize=(8,8))\n",
        "# # plt.imshow(label_roi_ts, cmap='jet')\n",
        "# # plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-56d7ec95329f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcnn_image_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_roi_ts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcnn_image_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_erosion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_image_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcnn_image_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcnn_image_ts\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cnn_predict' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ohueCXOyb47T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# plt.imshow(model.layers[0].get_weights()[0][0,0])\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iySICuKbmZ9i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "# with a Sequential model\n",
        "def get_conv_output(model,data,batch_size=512):\n",
        "  info = model.get_config()\n",
        "  flatten_layer = [i['class_name'] for i in info['layers']].index('Flatten')\n",
        "  get_batch_output = K.function([model.layers[0].input],[model.layers[flatten_layer].output])\n",
        "  \n",
        "  n = data.shape[0]\n",
        "  temp = np.expand_dims(data[0],axis=0)\n",
        "  out = get_batch_output([temp])[0]\n",
        "  out_size = out.shape[1]\n",
        "  ret = np.zeros((n,out_size))\n",
        "  \n",
        "  for i in np.arange(0,n,batch_size):\n",
        "    last = min(i+batch_size,n)\n",
        "    batch_data = data[i:last]\n",
        "    if batch_data.ndim == 3:\n",
        "      batch_data = np.expand_dims(batch_data,axis=0)\n",
        "\n",
        "    ret[i:last,:] = get_batch_output([batch_data])[0]\n",
        "  return ret\n",
        "\n",
        "# Get the convolution outputs as a flattened layer\n",
        "tr_conv_output = get_conv_output(model,data_tr)\n",
        "ts_conv_output = get_conv_output(model,data_ts)\n",
        "\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# scaler = StandardScaler()\n",
        "# scaler.fit(tr_conv_output)\n",
        "# tr_conv_output = scaler.transform(tr_conv_output)\n",
        "# ts_conv_output = scaler.transform(ts_conv_output)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EVbPlKzAYGCZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(data_tr_vector)\n",
        "dt = scaler.transform(data_tr_vector)\n",
        "ds = scaler.transform(data_ts_vector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oryDSrdrPkVW",
        "colab_type": "code",
        "outputId": "3f03a0f0-7d7a-40ab-b172-dc7b01ebd016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "import catboost\n",
        "import time\n",
        "\n",
        "\n",
        "gap = 1\n",
        "tr_data = tr_conv_output\n",
        "ts_data = ts_conv_output\n",
        "# tr_data = data_tr_vector\n",
        "# ts_data = data_ts_vector\n",
        "# tr_data = dt\n",
        "# ts_data = ds\n",
        "\n",
        "tr_label = label_tr\n",
        "ts_label = label_ts\n",
        "\n",
        "start_time = time.time()\n",
        "clf_rf = RandomForestClassifier(n_estimators=200,random_state=0)\n",
        "clf_rf.fit(tr_data[::gap],tr_label[::gap])\n",
        "score_rf = clf_rf.score(ts_data[::gap],ts_label[::gap])\n",
        "elapsed_time = time.time() - start_time\n",
        "print('Random Forest Classifier Accuracy is     {}, elapsed time: {}'.format(score_rf,elapsed_time))\n",
        "\n",
        "start_time = time.time()\n",
        "clf_svc = SVC(gamma='scale',random_state=0)\n",
        "clf_svc.fit(tr_data[::gap],tr_label[::gap])\n",
        "score_svc = clf_svc.score(ts_data[::gap],ts_label[::gap])\n",
        "elapsed_time = time.time() - start_time\n",
        "print('Support Vector Classifier Accuracy is    {}, elapsed_time: {}'.format(score_svc,elapsed_time))\n",
        "\n",
        "# start_time = time.time()\n",
        "# clf_cat = catboost.CatBoostClassifier(task_type='GPU',verbose=0,loss_function='MultiClass',random_state=0)\n",
        "# clf_cat.fit(tr_data[::gap],tr_label[::gap])\n",
        "# score_cat = clf_cat.score(ts_data[::gap],ts_label[::gap])\n",
        "# elapsed_time = time.time() - start_time\n",
        "# print('Catboost Classifier Accuracy is          {}, elapsed_time: {}'.format(score_cat,elapsed_time))\n",
        "\n",
        "start_time = time.time()\n",
        "clf_xgb = XGBClassifier()\n",
        "clf_xgb.fit(tr_data[::gap],tr_label[::gap])\n",
        "score_xgb = clf_xgb.score(ts_data[::gap],ts_label[::gap])\n",
        "elapsed_time = time.time() - start_time\n",
        "print('XGBoost Classifier Accuracy is           {}, elapsed_time: {}'.format(score_xgb,elapsed_time))\n",
        "\n",
        "start_time = time.time()\n",
        "clf_gbm = GradientBoostingClassifier(random_state=0)\n",
        "clf_gbm.fit(tr_data[::gap],tr_label[::gap])\n",
        "score_gbm = clf_gbm.score(ts_data[::gap],ts_label[::gap])\n",
        "elapsed_time = time.time() - start_time\n",
        "print('Gradient Boosting Classifier Accuracy is {}, elapsed_time: {}'.format(score_gbm,elapsed_time))\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "clf_nb = GaussianNB()\n",
        "clf_nb.fit(tr_data[::gap],tr_label[::gap])\n",
        "score_nb = clf_nb.score(ts_data[::gap],ts_label[::gap])\n",
        "elapsed_time = time.time() - start_time\n",
        "print('Naive Bayes Classifier Accuracy is      {}, elapsed time: {}'.format(score_nb,elapsed_time))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest Classifier Accuracy is     0.8080000479385667, elapsed time: 31.61854362487793\n",
            "Support Vector Classifier Accuracy is    0.8046398540270643, elapsed_time: 187.8006386756897\n",
            "XGBoost Classifier Accuracy is           0.8100059773400388, elapsed_time: 70.11176538467407\n",
            "Gradient Boosting Classifier Accuracy is 0.8080914308313896, elapsed_time: 65.21777963638306\n",
            "Naive Bayes Classifier Accuracy is      0.8158424978390193, elapsed time: 13.755285739898682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QLUrjpfI4uj4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gap=5\n",
        "pred_rf = clf_rf.predict(ts_data[::gap])\n",
        "pred_svc = clf_svc.predict(ts_data[::gap])\n",
        "pred_xgb = clf_xgb.predict(ts_data[::gap])\n",
        "pred_gbm = clf_gbm.predict(ts_data[::gap])\n",
        "pred_nb = clf_nb.predict(ts_data[::gap])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xliBkEOMSG5P",
        "colab_type": "code",
        "outputId": "0192e94d-8da0-465b-f3e2-a9651de0620c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "from scipy.stats import mode\n",
        "\n",
        "# pred_ens = np.vstack((pred_rf,pred_svc,pred_xgb,pred_gbm))\n",
        "# sum(label_ts == mode(pred_ens)[0][0])/len(label_ts)\n",
        "\n",
        "np.corrcoef(pred_rf,pred_nb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.89772051],\n",
              "       [0.89772051, 1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "EorBSPdth_V9",
        "colab_type": "code",
        "outputId": "c738fe59-64f0-47c6-90dd-0ae28ccc4bf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "import catboost\n",
        "import time\n",
        "\n",
        "\n",
        "gap = 1\n",
        "data_vector_tr = tr_conv_output\n",
        "data_vector_ts = ts_conv_output\n",
        "label_vector_tr = label_tr\n",
        "label_vector_ts = label_ts\n",
        "\n",
        "start_time = time.time()\n",
        "clf_rf = RandomForestClassifier(n_estimators=200,random_state=0)\n",
        "clf_rf.fit(data_vector_tr[::gap],label_vector_tr[::gap])\n",
        "score_rf = clf_rf.score(data_vector_ts[::gap],label_vector_ts[::gap])\n",
        "elapsed_time = time.time() - start_time\n",
        "print('Random Forest Classifier Accuracy is     {}, elapsed time: {}'.format(score_rf,elapsed_time))\n",
        "\n",
        "start_time = time.time()\n",
        "clf_svc = SVC(gamma='scale',random_state=0)\n",
        "clf_svc.fit(data_vector_tr[::gap],label_vector_tr[::gap])\n",
        "score_svc = clf_svc.score(data_vector_ts[::gap],label_vector_ts[::gap])\n",
        "elapsed_time = time.time() - start_time\n",
        "print('Support Vector Classifier Accuracy is    {}, elapsed_time: {}'.format(score_svc,elapsed_time))\n",
        "\n",
        "start_time = time.time()\n",
        "clf_cat = catboost.CatBoostClassifier(task_type='GPU',verbose=0,loss_function='MultiClass',random_state=0)\n",
        "clf_cat.fit(data_vector_tr[::gap],label_vector_tr[::gap])\n",
        "score_cat = clf_cat.score(data_vector_ts[::gap],label_vector_ts[::gap])\n",
        "elapsed_time = time.time() - start_time\n",
        "print('Catboost Classifier Accuracy is          {}, elapsed_time: {}'.format(score_cat,elapsed_time))\n",
        "\n",
        "start_time = time.time()\n",
        "clf_xgb = XGBClassifier()\n",
        "clf_xgb.fit(data_vector_tr[::gap],label_vector_tr[::gap])\n",
        "score_xgb = clf_xgb.score(data_vector_ts[::gap],label_vector_ts[::gap])\n",
        "elapsed_time = time.time() - start_time\n",
        "print('XGBoost Classifier Accuracy is           {}, elapsed_time: {}'.format(score_xgb,elapsed_time))\n",
        "\n",
        "start_time = time.time()\n",
        "clf_gbm = GradientBoostingClassifier(random_state=0)\n",
        "clf_gbm.fit(data_vector_tr[::gap],label_vector_tr[::gap])\n",
        "score_gbm = clf_gbm.score(data_vector_ts[::gap],label_vector_ts[::gap])\n",
        "elapsed_time = time.time() - start_time\n",
        "print('Gradient Boosting Classifier Accuracy is {}, elapsed_time: {}'.format(score_gbm,elapsed_time))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-faef154929f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mclf_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mclf_xgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_vector_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mgap\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_vector_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mgap\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mscore_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_xgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_vector_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mgap\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_vector_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mgap\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'XGBoost Classifier Accuracy is           {}, elapsed_time: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_xgb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0melapsed_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \"\"\"\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit)\u001b[0m\n\u001b[1;32m    524\u001b[0m         class_probs = self.get_booster().predict(test_dmatrix,\n\u001b[1;32m    525\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m                                                  ntree_limit=ntree_limit)\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0mcolumn_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs)\u001b[0m\n\u001b[1;32m   1050\u001b[0m                                           \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_uint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                                           \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m                                           ctypes.byref(preds)))\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes2numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "kqYSq0r-UJ25",
        "colab_type": "code",
        "outputId": "8d0cad58-d322-49d1-fcbf-65b9e623de62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3216
        }
      },
      "cell_type": "code",
      "source": [
        "# XgBoost cuda compile\n",
        "\n",
        "# !git clone https://github.com/dmlc/xgboost --recursive\n",
        "# !cd xgboost && mkdir build && cd build && cmake .. -DUSE_CUDA=ON && make -j4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- The C compiler identification is GNU 7.3.0\n",
            "-- The CXX compiler identification is GNU 7.3.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP: TRUE (found version \"4.5\")  \n",
            "-- Setting build type to 'Release' as none was specified.\n",
            "-- Looking for clock_gettime in rt\n",
            "-- Looking for clock_gettime in rt - found\n",
            "-- Looking for fopen64\n",
            "-- Looking for fopen64 - not found\n",
            "-- Looking for C++ include cxxabi.h\n",
            "-- Looking for C++ include cxxabi.h - found\n",
            "-- Looking for execinfo.h\n",
            "-- Looking for execinfo.h - found\n",
            "-- Looking for nanosleep\n",
            "-- Looking for nanosleep - found\n",
            "-- Check if the system is big endian\n",
            "-- Searching 16 bit integer\n",
            "-- Looking for sys/types.h\n",
            "-- Looking for sys/types.h - found\n",
            "-- Looking for stdint.h\n",
            "-- Looking for stdint.h - found\n",
            "-- Looking for stddef.h\n",
            "-- Looking for stddef.h - found\n",
            "-- Check size of unsigned short\n",
            "-- Check size of unsigned short - done\n",
            "-- Using unsigned short\n",
            "-- Check if the system is big endian - little endian\n",
            "-- /content/xgboost/dmlc-core/cmake/build_config.h.in -> /content/xgboost/dmlc-core/include/dmlc/build_config.h\n",
            "-- Performing Test SUPPORT_CXX11\n",
            "-- Performing Test SUPPORT_CXX11 - Success\n",
            "-- Performing Test SUPPORT_CXX0X\n",
            "-- Performing Test SUPPORT_CXX0X - Success\n",
            "-- Performing Test SUPPORT_MSSE2\n",
            "-- Performing Test SUPPORT_MSSE2 - Success\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n",
            "-- Looking for pthread.h\n",
            "-- Looking for pthread.h - found\n",
            "-- Looking for pthread_create\n",
            "-- Looking for pthread_create - not found\n",
            "-- Looking for pthread_create in pthreads\n",
            "-- Looking for pthread_create in pthreads - not found\n",
            "-- Looking for pthread_create in pthread\n",
            "-- Looking for pthread_create in pthread - found\n",
            "-- Found Threads: TRUE  \n",
            "-- Found CUDA: /usr/local/cuda (found suitable version \"9.2\", minimum required is \"8.0\") \n",
            "cuda architecture flags: -gencode arch=compute_35,code=sm_35;-gencode arch=compute_50,code=sm_50;-gencode arch=compute_52,code=sm_52;-gencode arch=compute_60,code=sm_60;-gencode arch=compute_61,code=sm_61;-gencode arch=compute_70,code=sm_70;-gencode arch=compute_70,code=compute_70;\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/xgboost/build\n",
            "\u001b[35m\u001b[1mScanning dependencies of target dmlc\u001b[0m\n",
            "[  1%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/gpuxgboost.dir/src/tree/gpuxgboost_generated_updater_gpu_hist.cu.o\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target rabit\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target objxgboost\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object dmlc-core/CMakeFiles/dmlc.dir/src/build_config.cc.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object CMakeFiles/rabit.dir/rabit/src/allreduce_base.cc.o\u001b[0m\n",
            "\u001b[01m\u001b[K/content/xgboost/dmlc-core/src/build_config.cc:14:6:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Redefining fopen64 with std::fopen\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            "     #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Redefining fopen64 with std::fopen\"\n",
            "      \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "[  5%] \u001b[32mBuilding CXX object dmlc-core/CMakeFiles/dmlc.dir/src/config.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/c_api/c_api.cc.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object dmlc-core/CMakeFiles/dmlc.dir/src/data.cc.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object CMakeFiles/rabit.dir/rabit/src/allreduce_robust.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/c_api/c_api_error.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object CMakeFiles/rabit.dir/rabit/src/engine.cc.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/common/common.cc.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object CMakeFiles/rabit.dir/rabit/src/c_api.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/common/hist_util.cc.o\u001b[0m\n",
            "[ 17%] \u001b[32m\u001b[1mLinking CXX static library librabit.a\u001b[0m\n",
            "[ 17%] Built target rabit\n",
            "[ 19%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/common/host_device_vector.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/data/data.cc.o\u001b[0m\n",
            "[ 21%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/gpuxgboost.dir/src/common/gpuxgboost_generated_common.cu.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/data/simple_csr_source.cc.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object dmlc-core/CMakeFiles/dmlc.dir/src/io.cc.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/data/simple_dmatrix.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object dmlc-core/CMakeFiles/dmlc.dir/src/recordio.cc.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object dmlc-core/CMakeFiles/dmlc.dir/src/io/line_split.cc.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/data/sparse_page_dmatrix.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object dmlc-core/CMakeFiles/dmlc.dir/src/io/recordio_split.cc.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object dmlc-core/CMakeFiles/dmlc.dir/src/io/indexed_recordio_split.cc.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/data/sparse_page_raw_format.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object dmlc-core/CMakeFiles/dmlc.dir/src/io/input_split_base.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/data/sparse_page_source.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object dmlc-core/CMakeFiles/dmlc.dir/src/io/filesys.cc.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/data/sparse_page_writer.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object dmlc-core/CMakeFiles/dmlc.dir/src/io/local_filesys.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/gbm/gblinear.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32m\u001b[1mLinking CXX static library libdmlc.a\u001b[0m\n",
            "[ 43%] Built target dmlc\n",
            "[ 45%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/gbm/gbm.cc.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/gbm/gbtree.cc.o\u001b[0m\n",
            "[ 47%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/gpuxgboost.dir/src/common/gpuxgboost_generated_hist_util.cu.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/learner.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/linear/linear_updater.cc.o\u001b[0m\n",
            "[ 52%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/gpuxgboost.dir/src/common/gpuxgboost_generated_host_device_vector.cu.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/linear/updater_coordinate.cc.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/linear/updater_shotgun.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/logging.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/metric/elementwise_metric.cc.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/metric/metric.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/metric/multiclass_metric.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/metric/rank_metric.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/objective/hinge.cc.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/objective/multiclass_obj.cc.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/objective/objective.cc.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/objective/rank_obj.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/objective/regression_obj.cc.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/predictor/cpu_predictor.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/predictor/predictor.cc.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/tree/split_evaluator.cc.o\u001b[0m\n",
            "[ 73%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/gpuxgboost.dir/src/linear/gpuxgboost_generated_updater_gpu_coordinate.cu.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/tree/tree_model.cc.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/tree/tree_updater.cc.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/tree/updater_colmaker.cc.o\u001b[0m\n",
            "[ 79%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/gpuxgboost.dir/src/metric/gpuxgboost_generated_elementwise_metric.cu.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/tree/updater_histmaker.cc.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/tree/updater_prune.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/tree/updater_quantile_hist.cc.o\u001b[0m\n",
            "[ 84%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/tree/updater_refresh.cc.o\u001b[0m\n",
            "[ 86%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/tree/updater_skmaker.cc.o\u001b[0m\n",
            "[ 87%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/gpuxgboost.dir/src/objective/gpuxgboost_generated_hinge.cu.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object CMakeFiles/objxgboost.dir/src/tree/updater_sync.cc.o\u001b[0m\n",
            "[ 89%] Built target objxgboost\n",
            "[ 90%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/gpuxgboost.dir/src/objective/gpuxgboost_generated_multiclass_obj.cu.o\u001b[0m\n",
            "[ 91%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/gpuxgboost.dir/src/objective/gpuxgboost_generated_regression_obj.cu.o\u001b[0m\n",
            "[ 93%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/gpuxgboost.dir/src/predictor/gpuxgboost_generated_gpu_predictor.cu.o\u001b[0m\n",
            "[ 94%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/gpuxgboost.dir/src/tree/gpuxgboost_generated_updater_gpu.cu.o\u001b[0m\n",
            "/content/xgboost/src/tree/updater_gpu.cu(112): warning: function \"__shfl_up(int, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(174): here was declared deprecated (\"__shfl_up() is not valid on compute_70 and above, and should be replaced with __shfl_up_sync().To continue using __shfl_up(), specify virtual architecture compute_60 when targeting sm_70 and above, for example, using the pair of compiler options: -arch=compute_60 -code=sm_70.\")\n",
            "          detected during instantiation of \"void xgboost::tree::reduceScanByKey(xgboost::GradientPair *, xgboost::GradientPair *, const xgboost::GradientPair *, const int *, const xgboost::tree::NodeIdT *, int, int, int, xgboost::GradientPair *, int *, const int *, xgboost::tree::NodeIdT) [with BLKDIM_L1L3=256, BLKDIM_L2=512]\" \n",
            "(615): here\n",
            "\n",
            "/content/xgboost/src/tree/updater_gpu.cu(112): warning: function \"__shfl_up(int, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(174): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "          detected during instantiation of \"void xgboost::tree::reduceScanByKey(xgboost::GradientPair *, xgboost::GradientPair *, const xgboost::GradientPair *, const int *, const xgboost::tree::NodeIdT *, int, int, int, xgboost::GradientPair *, int *, const int *, xgboost::tree::NodeIdT) [with BLKDIM_L1L3=256, BLKDIM_L2=512]\" \n",
            "(615): here\n",
            "\n",
            "ptxas /tmp/tmpxft_0000099c_00000000-10_updater_gpu.compute_35.ptx, line 1879; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "/content/xgboost/src/tree/updater_gpu.cu(112): warning: function \"__shfl_up(int, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(174): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "          detected during instantiation of \"void xgboost::tree::reduceScanByKey(xgboost::GradientPair *, xgboost::GradientPair *, const xgboost::GradientPair *, const int *, const xgboost::tree::NodeIdT *, int, int, int, xgboost::GradientPair *, int *, const int *, xgboost::tree::NodeIdT) [with BLKDIM_L1L3=256, BLKDIM_L2=512]\" \n",
            "(615): here\n",
            "\n",
            "ptxas /tmp/tmpxft_0000099c_00000000-9_updater_gpu.compute_50.ptx, line 1879; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "/content/xgboost/src/tree/updater_gpu.cu(112): warning: function \"__shfl_up(int, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(174): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "          detected during instantiation of \"void xgboost::tree::reduceScanByKey(xgboost::GradientPair *, xgboost::GradientPair *, const xgboost::GradientPair *, const int *, const xgboost::tree::NodeIdT *, int, int, int, xgboost::GradientPair *, int *, const int *, xgboost::tree::NodeIdT) [with BLKDIM_L1L3=256, BLKDIM_L2=512]\" \n",
            "(615): here\n",
            "\n",
            "ptxas /tmp/tmpxft_0000099c_00000000-8_updater_gpu.compute_52.ptx, line 1879; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "/content/xgboost/src/tree/updater_gpu.cu(112): warning: function \"__shfl_up(int, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(174): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "          detected during instantiation of \"void xgboost::tree::reduceScanByKey(xgboost::GradientPair *, xgboost::GradientPair *, const xgboost::GradientPair *, const int *, const xgboost::tree::NodeIdT *, int, int, int, xgboost::GradientPair *, int *, const int *, xgboost::tree::NodeIdT) [with BLKDIM_L1L3=256, BLKDIM_L2=512]\" \n",
            "(615): here\n",
            "\n",
            "ptxas /tmp/tmpxft_0000099c_00000000-7_updater_gpu.compute_60.ptx, line 1879; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "/content/xgboost/src/tree/updater_gpu.cu(112): warning: function \"__shfl_up(int, unsigned int, int)\"\n",
            "/usr/local/cuda/include/sm_30_intrinsics.hpp(174): here was declared deprecated (\"__shfl_up() is deprecated in favor of __shfl_up_sync() and may be removed in a future release (Use -Wno-deprecated-declarations to suppress this warning).\")\n",
            "          detected during instantiation of \"void xgboost::tree::reduceScanByKey(xgboost::GradientPair *, xgboost::GradientPair *, const xgboost::GradientPair *, const int *, const xgboost::tree::NodeIdT *, int, int, int, xgboost::GradientPair *, int *, const int *, xgboost::tree::NodeIdT) [with BLKDIM_L1L3=256, BLKDIM_L2=512]\" \n",
            "(615): here\n",
            "\n",
            "ptxas /tmp/tmpxft_0000099c_00000000-6_updater_gpu.compute_61.ptx, line 1879; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "ptxas /tmp/tmpxft_0000099c_00000000-5_updater_gpu.compute_70.ptx, line 1879; warning : Instruction 'shfl' without '.sync' may produce unpredictable results on sm_70 and later architectures\n",
            "ptxas /tmp/tmpxft_0000099c_00000000-5_updater_gpu.compute_70.ptx, line 1879; warning : Instruction 'shfl' without '.sync' is deprecated since PTX ISA version 6.0 and will be discontinued in a future PTX ISA version\n",
            "CMakeFiles/gpuxgboost.dir/build.make:126: recipe for target 'CMakeFiles/gpuxgboost.dir/src/tree/gpuxgboost_generated_updater_gpu.cu.o' failed\n",
            "make[2]: *** [CMakeFiles/gpuxgboost.dir/src/tree/gpuxgboost_generated_updater_gpu.cu.o] Interrupt\n",
            "CMakeFiles/gpuxgboost.dir/build.make:91: recipe for target 'CMakeFiles/gpuxgboost.dir/src/metric/gpuxgboost_generated_elementwise_metric.cu.o' failed\n",
            "make[2]: *** [CMakeFiles/gpuxgboost.dir/src/metric/gpuxgboost_generated_elementwise_metric.cu.o] Interrupt\n",
            "CMakeFiles/Makefile2:109: recipe for target 'CMakeFiles/gpuxgboost.dir/all' failed\n",
            "make[1]: *** [CMakeFiles/gpuxgboost.dir/all] Interrupt\n",
            "Makefile:129: recipe for target 'all' failed\n",
            "make: *** [all] Interrupt\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4VBD0_KeEH8k",
        "colab_type": "code",
        "outputId": "5f8844f0-cfc5-4852-9e02-4a75cba3c529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import lightgbm as lgb\n",
        "d_train = lgb.Dataset(tr_conv_output[::1], label=label_tr[::1])\n",
        "params = {}\n",
        "params['learning_rate'] = 0.1\n",
        "params['boosting_type'] = 'gbdt'\n",
        "params['objective'] = 'multiclass'\n",
        "params['metric'] = 'multi_logloss'\n",
        "params['feature_fraction'] = 0.9\n",
        "params['bagging_fraction'] = 0.8\n",
        "params['bagging_freq'] = 5\n",
        "params['num_class'] = 11\n",
        "params['sub_feature'] = 0.5\n",
        "params['num_leaves'] = 10\n",
        "params['min_data'] = 50\n",
        "params['max_depth'] = 5\n",
        "# params['device_type'] = 'gpu'\n",
        "gbm = lgb.train(params, d_train,num_boost_round=30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 20min 3s, sys: 2.69 s, total: 20min 6s\n",
            "Wall time: 10min 23s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oHuoIve5MCIg",
        "colab_type": "code",
        "outputId": "1d581c2d-e7a0-4cd0-8f0f-344a98dd7191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "pred_gbm = gbm.predict(ts_conv_output, num_iteration=gbm.best_iteration)\n",
        "pred_gbm_r = np.argmax(pred_gbm,axis=1)\n",
        "print(np.sum(pred_gbm_r == label_ts)/label_ts.shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7202559702559702\n",
            "CPU times: user 6.3 s, sys: 9.9 ms, total: 6.31 s\n",
            "Wall time: 3.27 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J2LpGoK3Ilzd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !pip install pydot\n",
        "# !pip install pydotplus\n",
        "# !pip install graphviz\n",
        "# from keras.utils import plot_model\n",
        "# plot_model(model, to_file='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TykDoakwJ5_z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from __future__ import print_function\n",
        "\n",
        "# import keras\n",
        "# from keras.datasets import mnist\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
        "# from keras.layers import Conv2D, MaxPooling2D\n",
        "# from keras.optimizers import RMSprop\n",
        "# from sklearn import preprocessing\n",
        "\n",
        "# batch_size = 1024\n",
        "# num_classes = 11\n",
        "# epochs = 10\n",
        "\n",
        "# label_tr_cat = keras.utils.to_categorical(label_tr, num_classes)\n",
        "# label_ts_cat = keras.utils.to_categorical(label_ts, num_classes)\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Conv2D(256, kernel_size=(5, 5),\n",
        "#                  activation='relu',\n",
        "#                  input_shape=(16,16,6)))\n",
        "\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Conv2D(512, kernel_size=(3, 3),\n",
        "#                  activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Conv2D(1024, kernel_size=(3, 3),\n",
        "#                  activation='relu'))\n",
        "\n",
        "# # model.add(Conv2D(128, (3, 3), activation='elu'))\n",
        "# # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Flatten())\n",
        "# model.add(BatchNormalization())\n",
        "\n",
        "# num_layers = 4\n",
        "# n_neurons = 256\n",
        "# scaling_factor = 2\n",
        "# drop_out = 0.1\n",
        "# drop_out_increment = 0.0125\n",
        "\n",
        "# for i in np.arange(num_layers):\n",
        "#   model.add(Dense(n_neurons, activation='relu'))\n",
        "#   model.add(BatchNormalization())\n",
        "#   model.add(Dropout(drop_out))\n",
        "#   n_neurons = int(n_neurons / scaling_factor)\n",
        "#   drop_out += drop_out_increment\n",
        "# model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "#               optimizer=keras.optimizers.Adadelta(),\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# model.fit(data_tr, label_tr_cat,\n",
        "#           batch_size=batch_size,\n",
        "#           epochs=epochs,\n",
        "#           verbose=1,validation_data=(data_ts, label_ts_cat))\n",
        "\n",
        "# # score = model.evaluate(data_ts, label_ts_cat, verbose=0)\n",
        "# # print('Test loss:', score[0])\n",
        "# # print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kgVZ-iKc6Hwd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from sklearn.ensemble import ExtraTreesClassifier\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "# clf_tree = DecisionTreeClassifier(random_state=0,)\n",
        "# label_tree = cross_val_predict(clf_tree, data_cat, label_cat, cv=5)\n",
        "# # print(scores_tree.mean())\n",
        "\n",
        "# clf_extree = ExtraTreesClassifier(n_estimators=50,n_jobs=-1, random_state=0)\n",
        "# label_extree = cross_val_score(clf_extree, data_cat, label_cat, cv=5)\n",
        "# # print(scores_extree.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mJf1WQob5GuT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # np.log(np.real(data_forest+1e-6))\n",
        "# # plt.imshow(np.exp(np.real(data_img[:,:,0]*10).astype(float)))\n",
        "# # plt.show()\n",
        "# # np.exp(np.real(data_img[:,:,0]*10))\n",
        "\n",
        "# pred_cnn = model.predict(data_ts,\n",
        "#           batch_size=batch_size,\n",
        "#           verbose=1)\n",
        "# cnn_classes = pred_cnn.argmax(axis=-1)\n",
        "\n",
        "# import pandas as pd\n",
        "\n",
        "# df = pd.DataFrame()\n",
        "# df['label'] = label_ts\n",
        "# df['CNN'] = cnn_classes\n",
        "\n",
        "# # df\n",
        "# pd.crosstab(df['label'],df['CNN'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}